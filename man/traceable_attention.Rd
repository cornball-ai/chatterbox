% Generated by rhydrogen: do not edit by hand
% Please edit documentation in R/llama_traced.R
\name{traceable_attention}
\alias{traceable_attention}
\title{Traceable attention module with pre-allocated KV cache}
\usage{
traceable_attention(attn, max_cache_len = 300L)
}
\arguments{
\item{attn}{Original llama_attention module}

\item{max_cache_len}{Maximum cache length}
}
\value{
nn_module
}
\description{
This module is designed to be traced with jit_trace. It uses:
- Pre-allocated KV cache of fixed max size
- Attention mask to indicate valid cache positions
- Returns only output tensor (no lists/dicts)
}
